{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"O-nZ59Vf97pK"},"outputs":[],"source":["# -*- coding: utf-8 -*-\n","# -*- authors : Vincent Roduit, Filippo Quadri -*-\n","# -*- date : 2024-05-03 -*-\n","# -*- Last revision: 2024-05-21 -*-\n","# -*- python version : 3.9.18 -*-\n","# -*- Description: Notebook that summarize results-*-"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2636,"status":"ok","timestamp":1716201016472,"user":{"displayName":"Vincent Roduit","userId":"13076277421100865046"},"user_tz":-120},"id":"6941kpJ89_mu","outputId":"33378dac-55c1-4276-f54c-e5a627dc8b18"},"outputs":[],"source":["#Prepare Google Colab Environment\n","from google.colab import drive\n","drive.mount('/content/drive')\n","%cd /content/drive/MyDrive/EE-451-IAPR/project/src"]},{"cell_type":"markdown","metadata":{"id":"ZGn195Dx97pN"},"source":["# <center> EE - 451 Image Analysis and Pattern recognition </center>\n","## <center> Ecole Polytechnique Fédérale de Lausanne </center>\n","### <center>Coin Challenge </center>\n","---"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":403,"status":"ok","timestamp":1716203346578,"user":{"displayName":"Vincent Roduit","userId":"13076277421100865046"},"user_tz":-120},"id":"7K7Y8PkC97pP"},"outputs":[],"source":["#Import libraries\n","import torch\n","import importlib\n","from torch.optim.lr_scheduler import ReduceLROnPlateau\n","from torch import nn\n","import timm\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"code","execution_count":181,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":305,"status":"ok","timestamp":1716205344981,"user":{"displayName":"Vincent Roduit","userId":"13076277421100865046"},"user_tz":-120},"id":"UTG2yckF97pP","outputId":"aeac256e-fa6a-46e8-ea8b-c22cbdc14004"},"outputs":[{"name":"stdout","output_type":"stream","text":["The autoreload extension is already loaded. To reload it, use:\n","  %reload_ext autoreload\n"]}],"source":["#Import files\n","import constants\n","importlib.reload(constants)\n","\n","#Classes\n","from data_classes.ref_data import refCoin\n","from data_classes.train_data import trainCoin\n","from data_classes.test_data import testCoin\n","\n","#Functions\n","from visualization import *\n","from pickle_func import *\n","from pre_processing.process_func import *\n","from post_processing.data_augmentation import *\n","from post_processing.data_formating import *\n","from post_processing.dataloader import *\n","from post_processing.submission import *\n","from pre_processing.feature_extraction import *\n","\n","#Models\n","from models.cnn import Basic_CNN, Advanced_CNN, CnnRadius\n","%load_ext autoreload\n","%autoreload 2\n"]},{"cell_type":"markdown","metadata":{},"source":["The project is structured as follow:\n","```\n",".\n","├── data\n","│   ├── ref\n","│   ├── results\n","│   ├── test\n","│   ├── train\n","│   └── train_labels.csv\n","├── documents\n","│   └── IAPR_Project_2024.pdf\n","├── environment.yml\n","├── requirements.txt\n","├── src\n","│   ├── constants.py\n","│   ├── data_classes\n","│   ├── main.ipynb\n","│   ├── main.py\n","│   ├── models\n","│   ├── pickle_func.py\n","│   ├── post_processing\n","│   ├── pre_processing\n","│   └── visualization.py\n","└── submissions\n","    └── sample_submission.csv\n","```\n","\n","The code can be found under the src folder. Furthermore, subfolders are created to organize better the project structure. All the function responsible of the pre processing (segmentation) can be found in the dedicated folder. The same applies for the post processing, responsible for the data augmentation as well as the formating for the neural network classifier."]},{"cell_type":"markdown","metadata":{"id":"_5wZnAr697pQ"},"source":["# 1. Load different Datasets"]},{"cell_type":"markdown","metadata":{},"source":["The first part of the process is to load the different images. Each type of data has its associated class, resp. `refCoin`, `trainCoin` and `testCoin`, in order to simplify the treatment. To save time, the attribute `save` can be set to false to avoid saving the result in the different folders.\n","If it is set to True, data are saved under the results folder: \n","```\n",".\n","├── data\n","│   ├── ref\n","│   ├── results\n","│   ├── test\n","│   ├── train\n","│   └── train_labels.csv\n","```\n","\n","Furthermore, the raw images as well as the indexes (image name) are automatically saved as pickle files to save time. These pickles are saved under `../data/{class_name}/pickle_files`. Once created these files are automatically loaded the next time the constructor is called."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-JGPRvL197pR","outputId":"937bba94-8957-47a3-e8a2-620ef6f82279"},"outputs":[],"source":["ref_data = refCoin(save=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"29XCNbx397pR","outputId":"76e21ae1-d069-4441-a913-425f826cae4d"},"outputs":[],"source":["train_data = trainCoin(save=False)"]},{"cell_type":"code","execution_count":99,"metadata":{"id":"95YGqtKe97pS","outputId":"756b3f8d-e599-40c7-9f71-8b4e2aee2f1a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Loading data from pickle files\n"]}],"source":["test_data = testCoin(save=False)"]},{"cell_type":"markdown","metadata":{"id":"uaoCU_3M97pS"},"source":["# 2 Data Processing"]},{"cell_type":"markdown","metadata":{},"source":["The next part of the process is to detect the coins in the different images and create single image for each coin. The class function **proceed_data** does the whole analysis. This analysis can be decomposed into several parts.\n","\n","1. Finding contours:  \n","   The first step of the process is to find the contours. In order to effectively detect the contours, depending on the background properties, these steps are performed:\n","   - First of all, the image is reshaped (1/4) in order to accelerate the computation time. 1/4 was a good compromise between speed and image quality.\n","   - In order to distinguish the backgrounds, the standard deviation of the image is calculated. Conditions on this threshold are then set. The idea behind using the standard deviation is that the higher the standard deviation is, the more filtered the image should be. As the different backgrounds (neutral, hand, and noisy) have different structuring elements, this aims to be a good choice. To differentiate between the hand and the noisy background, the standard deviation of the contours is used: the noisy background will create a lot of small contours, while the hand will create fewer, resulting in a difference in standard deviation.\n","   - To find the contours itselfs, the images are then converted into grayscale. A lowpass filter (Gaussian blur) is then applied in order to reduce the noise in the image. A high pass is also created and applied to the image. The image is then thresholded on the resulting image.\n","   - Morphology is applied in order to clean the image and make it easier to detect the coins. First, small objects are removed and then a closing is done. \n","   - The last step is to find the contours (using cv.HoughCircles). \n","\n","   This process gives very good results (1 coin is not detected in the train set(superposed coins) and two are not detected in the test set)\n","\n","2. Create the masked images:\n","   Now that the coins are efficiently detected, a masked image is created on the original image. This is done in order to have a perfect contours on the coins. These masked images are again stored both as a dictionary (attribute of the class) and as a tuple in order to save informations about the image. These tuples have the following shape: \\\n","   `(image_name, coin_name, contour)` \\\n","   for instance:\\\n","   `('L1010410', 'L1010410_0', array([812.5, 582.5,  53.6], dtype=float32))`. \n","3. The last step of the process is to crop the coins. For each image, coins are detoured and return a croped image of variable shape. These croped images are stored as an array."]},{"cell_type":"markdown","metadata":{},"source":["## 2.1 Segmentation"]},{"cell_type":"markdown","metadata":{},"source":["### 2.1.1 Performing the segmentation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZKWiHjoQ97pT","outputId":"b467915f-cc84-4905-d6f0-51807cd7d88f"},"outputs":[],"source":["#Process all the images :\n","# 1. clean the images and find the contours\n","# 2. create the masked images\n","# 3. create the coin images\n","# 4. if save = True, save the images and the class in a result folder\n","train_data.proceed_data()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"O6eN8TorbrPp"},"outputs":[],"source":["ref_data.proceed_data()"]},{"cell_type":"code","execution_count":100,"metadata":{"id":"MBHFQKtfbrPp","outputId":"b1baa5c3-a6a6-4a67-9a35-1ae74d4d2811"},"outputs":[{"name":"stdout","output_type":"stream","text":["Finding contours\n","Creating masked images\n","Creating coin images\n"]}],"source":["test_data.proceed_data()"]},{"cell_type":"markdown","metadata":{},"source":["## 2.1.2 Visualization"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["contour_images = construct_contour_images(train_data.raw_data, train_data.contours)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plot_side_by_side(\n","    original_images=train_data.raw_data,\n","    processed_images=contour_images,\n","    index=3,\n","    title1='Original Image',\n","    title2='Image with Contours'\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plot_side_by_side(\n","    original_images=train_data.raw_data, \n","    processed_images=train_data.image_masked, \n","    index=3, \n","    title1='Original Image', \n","    title2='Masked Image')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plot_crop_coins(train_data.coins)"]},{"cell_type":"markdown","metadata":{},"source":["# 3 Classification"]},{"cell_type":"markdown","metadata":{},"source":["Now that the images have been segmented, each coin must be associated with its corresponding label. However, due to the use of Weak Supervision in the train labels (train_labels.csv), direct assignment of coins to their respective classes is not feasible.\n","\n","One possible approach is manual labeling of the entire training set. Given the relatively low number of training samples (less than 400 samples), manual labeling is a viable option. Initially, this method was employed in the project to facilitate subsequent tasks such as classifier construction. However, it's important to note the inherent limitations of this technique. With a larger number of samples, the time and effort required for manual labeling would become prohibitively high, rendering it impractical. Consequently, alternative strategies need to be explored."]},{"cell_type":"markdown","metadata":{},"source":["## 3.1 Automatic labelisation"]},{"cell_type":"markdown","metadata":{},"source":["An attempt was made to automate the labeling process. This involved several key steps:\n","\n","1. Feature Selection:\n","    Identifying effective features is crucial for optimal class separation. In this context, multiple features were utilized:\n","    - LBP features (Local Binary Pattern)\n","    - Average color of the image\n","    - Image size\n","\n","2. Application of Unsupervised Learning:\n","    Following feature extraction, the data was partitioned into the requisite number of classes (16 in this instance). To achieve this, a Gaussian Mixture Model was employed. Additionally, to mitigate the curse of dimensionality, Principal Component Analysis (PCA) was conducted to reduce the input dimensionality.\n","\n","3. Mapping Labels to Ground Truth:\n","    The final step involved associating the identified labels with the actual labels provided by the *train_label.csv* file. To accomplish this task, the Hungarian Algorithm was utilized. This algorithm is a combinatorial optimization technique that establishes relationships between the number of samples found in each cluster and the actual count of elements per category.\n","\n","Despite these efforts, the accuracy of this approach was unsatisfactory, precluding its continuation for subsequent stages of the project.\n"]},{"cell_type":"code","execution_count":54,"metadata":{},"outputs":[],"source":["coin_images = [coin for _,_,coin in train_data.coins]"]},{"cell_type":"code","execution_count":65,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Silhouette Score: 0.23338638292939937\n","Cluster 0 is mapped to coin type 13, which is a 0.05EUR \n","Cluster 1 is mapped to coin type 10, which is a 0.5EUR \n","Cluster 2 is mapped to coin type 16, which is a OOD\n","Cluster 3 is mapped to coin type 6, which is a 0.1CHF \n","Cluster 4 is mapped to coin type 2, which is a 2CHF \n","Cluster 5 is mapped to coin type 7, which is a 0.05CHF \n","Cluster 6 is mapped to coin type 14, which is a 0.02EUR \n","Cluster 7 is mapped to coin type 8, which is a 2EUR \n","Cluster 8 is mapped to coin type 11, which is a 0.2EUR \n","Cluster 9 is mapped to coin type 12, which is a 0.1EUR \n","Cluster 10 is mapped to coin type 9, which is a 1EUR \n","Cluster 11 is mapped to coin type 15, which is a 0.01EUR \n","Cluster 12 is mapped to coin type 1, which is a 5CHF \n","Cluster 13 is mapped to coin type 3, which is a 1CHF \n","Cluster 14 is mapped to coin type 5, which is a 0.2CHF \n","Cluster 15 is mapped to coin type 4, which is a 0.5CHF \n"]}],"source":["coin_labels_auto = associate_labels(coin_images)"]},{"cell_type":"markdown","metadata":{"id":"Qmr1XfI_bIe-"},"source":["## 3.2 Fetch the labels (hand)"]},{"cell_type":"markdown","metadata":{},"source":["This second method uses the labels done by hand. It ensures to have 100% accuracy for the rest of the process.\n","First, a conversion table is builded to match the text label (e.g. 5CHF) to an int representation. A DataFrame, coin_labels summarizes all the informations about the coins labels and the coin image name.\n","\n","A next step will be to regroup all the informations (image name, coin name, the coin image, the label, the radius) in a single place to proceed to the classification. This is done by the functions `create_train_data_structure` and `create_test_data_structure`"]},{"cell_type":"code","execution_count":56,"metadata":{"executionInfo":{"elapsed":266,"status":"ok","timestamp":1716202304362,"user":{"displayName":"Vincent Roduit","userId":"13076277421100865046"},"user_tz":-120},"id":"d1FW4ji797pT"},"outputs":[],"source":["conversion_table = get_classes_conv_table()"]},{"cell_type":"code","execution_count":64,"metadata":{"id":"6s1vxbmk97pT"},"outputs":[],"source":["# Associate the labels to the coins\n","coin_labels = get_coin_labels()"]},{"cell_type":"code","execution_count":95,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>image_name</th>\n","      <th>Label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>L1010277_0</td>\n","      <td>5CHF</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>L1010277_1</td>\n","      <td>0.5EUR</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>L1010277_2</td>\n","      <td>0.2EUR</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>L1010277_3</td>\n","      <td>2EUR</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>L1010277_4</td>\n","      <td>0.2EUR</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   image_name   Label\n","0  L1010277_0    5CHF\n","1  L1010277_1  0.5EUR\n","2  L1010277_2  0.2EUR\n","3  L1010277_3    2EUR\n","4  L1010277_4  0.2EUR"]},"metadata":{},"output_type":"display_data"}],"source":["display(coin_labels.head(5))"]},{"cell_type":"markdown","metadata":{},"source":["Test the similarity between the two methods"]},{"cell_type":"code","execution_count":93,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["The accuracy of the automatic labeling is 0.05235602094240838\n"]}],"source":["coin_labels_values = np.array([conversion_table[label] for label in coin_labels['Label']])\n","accuracy = np.sum(np.array(coin_labels_auto) == coin_labels_values) / len(coin_labels_values)\n","print(f'The accuracy of the automatic labeling is {accuracy}')"]},{"cell_type":"code","execution_count":96,"metadata":{"id":"GfKkLy3w97pU"},"outputs":[],"source":["# Extract the images and the labels + create a dataframe that summarize the data\n","train_images_raw, train_radius_infos, labels, df_train_images_labels = create_train_data_structure(train_data.coins, train_data.contours_tuple, coin_labels,conversion_table)"]},{"cell_type":"code","execution_count":98,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>image_name</th>\n","      <th>coin_name</th>\n","      <th>label</th>\n","      <th>label_int</th>\n","      <th>contour</th>\n","      <th>radius</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>L1010410</td>\n","      <td>L1010410_0</td>\n","      <td>0.5CHF</td>\n","      <td>3</td>\n","      <td>[812.5, 582.5, 53.6]</td>\n","      <td>53.599998</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>L1010410</td>\n","      <td>L1010410_1</td>\n","      <td>OOD</td>\n","      <td>15</td>\n","      <td>[876.5, 427.5, 76.4]</td>\n","      <td>76.400002</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>L1010410</td>\n","      <td>L1010410_2</td>\n","      <td>0.1EUR</td>\n","      <td>11</td>\n","      <td>[703.5, 434.5, 58.0]</td>\n","      <td>58.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  image_name   coin_name   label  label_int               contour     radius\n","0   L1010410  L1010410_0  0.5CHF          3  [812.5, 582.5, 53.6]  53.599998\n","1   L1010410  L1010410_1     OOD         15  [876.5, 427.5, 76.4]  76.400002\n","2   L1010410  L1010410_2  0.1EUR         11  [703.5, 434.5, 58.0]  58.000000"]},"metadata":{},"output_type":"display_data"}],"source":["display(df_train_images_labels.head(3))"]},{"cell_type":"code","execution_count":101,"metadata":{"id":"wXlaQh5FbrPq"},"outputs":[],"source":["test_imgs, test_radius_infos, df_test_images = create_test_data_structure(test_data.coins, test_data.contours_tuple)"]},{"cell_type":"code","execution_count":102,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>image_name</th>\n","      <th>coin_name</th>\n","      <th>contour</th>\n","      <th>radius</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>L0000106</td>\n","      <td>L0000106_0</td>\n","      <td>[566.5, 215.5, 69.8]</td>\n","      <td>69.800003</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>L0000106</td>\n","      <td>L0000106_1</td>\n","      <td>[319.5, 431.5, 64.6]</td>\n","      <td>64.599998</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>L0000106</td>\n","      <td>L0000106_2</td>\n","      <td>[436.5, 327.5, 62.8]</td>\n","      <td>62.799999</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  image_name   coin_name               contour     radius\n","0   L0000106  L0000106_0  [566.5, 215.5, 69.8]  69.800003\n","1   L0000106  L0000106_1  [319.5, 431.5, 64.6]  64.599998\n","2   L0000106  L0000106_2  [436.5, 327.5, 62.8]  62.799999"]},"metadata":{},"output_type":"display_data"}],"source":["display(df_test_images.head(3))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UQOnhQU0brPq"},"outputs":[],"source":["# Optional: Save the data in pickle files to avoid reprocessing the data\n","#           The data can be loaded using the load_pickle function\n","#           The data is saved in the folder ../data/results/pickle_files   \n","save_pickle(test_imgs, 'test_imgs.pkl')\n","save_pickle(test_radius_infos, 'test_radius_infos.pkl')\n","save_pickle(df_test_images, 'df_test_images.pkl')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d5DSzvkP97pU"},"outputs":[],"source":["# Optional : save the coins in ../data/results/coins_classified\n","#           the coins are separated in folders according to their class\n","save_coins_classified(df_train_images_labels, train_images_raw)"]},{"cell_type":"markdown","metadata":{"id":"JJfDYX1kbIe_"},"source":["## 3.3 Data augmentation and train/validation split"]},{"cell_type":"markdown","metadata":{},"source":["The next step before classification is to separate the training values into training and validation sets. The ratio is set in the **constants.py** file.\n","\n","Data augmentation is also performed to improve the results and expand the training set. Several methods have been used:\n","- **Rotations**: Rotations are applied to ensure the model can recognize coins from every direction.\n","- **Gaussian Blur**: With a certain probability, Gaussian blur is applied to images to enhance the model's robustness.\n","- **Gamma Correction**: This augmentation is used to correct the difference in luminescence in the image. \n","    - Gamma > 1: Darkens the image.\n","    - Gamma < 1: Brightens the image.\n"]},{"cell_type":"code","execution_count":104,"metadata":{"id":"qhElOdHX97pU"},"outputs":[],"source":["# Create the splits (train and validation)\n","train_images, train_radius, train_labels, val_images, val_radius, val_labels = create_splits(train_images_raw, train_radius_infos, labels)"]},{"cell_type":"code","execution_count":196,"metadata":{"id":"z2MkspQE97pU"},"outputs":[],"source":["# Augment the training set with rotations\n","train_images_aug, train_radius_aug, train_labels_aug = augment_set_rotations(train_images, train_radius, train_labels)\n","\n","# Augment the training set with Gaussian blur\n","train_images_aug, train_radius_aug, train_labels_aug = augment_blur(train_images_aug,train_radius_aug, train_labels_aug)\n","\n","# Augment the training set with histogram equalization\n","train_images_aug, train_radius_aug, train_labels_aug = augment_histogram_equalization(train_images_aug, train_radius_aug, train_labels_aug)\n","\n","# Augment the training set with gamma correction\n","train_images_aug, train_radius_aug, train_labels_aug = augment_gamma_correction(train_images_aug, train_radius_aug, train_labels_aug)"]},{"cell_type":"markdown","metadata":{},"source":["Save the resultings arrays in pickle format in order to save time. These array can be directly loaded when needed"]},{"cell_type":"code","execution_count":211,"metadata":{"id":"6k1nLFlbbIfA"},"outputs":[],"source":["#Optional : save the datasets in ../data/results/pickle_files\n","save_pickle(result=train_images_aug, file_name='train_images_aug_resized.pkl')\n","save_pickle(result=train_radius_aug, file_name='train_radius_aug.pkl')\n","save_pickle(result=train_labels_aug, file_name='train_labels_aug.pkl')\n","\n","save_pickle(result=val_images, file_name='val_images_resized.pkl')\n","save_pickle(result=val_radius, file_name='val_radius.pkl')\n","save_pickle(result=val_labels, file_name='val_labels.pkl')"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":2354,"status":"ok","timestamp":1716202349619,"user":{"displayName":"Vincent Roduit","userId":"13076277421100865046"},"user_tz":-120},"id":"6yY0F4U_-NU8"},"outputs":[],"source":["# Optional : Load precomputed data\n","train_images_aug_resized = load_pickle('train_images_aug_resized.pkl')\n","train_images_labels_aug = load_pickle('train_labels_aug.pkl')\n","train_radius_aug = load_pickle('train_radius_aug.pkl')\n","\n","val_images_resized = load_pickle('val_images_resized.pkl')\n","val_radius = load_pickle('val_radius.pkl')\n","val_images_labels = load_pickle('val_labels.pkl')\n","\n","test_imgs = load_pickle('test_imgs.pkl')\n","test_radius_infos = load_pickle('test_radius_infos.pkl')\n","df_test_images = load_pickle('df_test_images.pkl')"]},{"cell_type":"markdown","metadata":{"id":"jTOA14mK97pV"},"source":["# 4 Train Neural Network\n"]},{"cell_type":"markdown","metadata":{},"source":["To perform the classification, a neural network has been chosen. More precisely a Convolutional Neural Network has been chosen. This kind of neural network has shown very high performance for computer vision tasks. For this projects, several models are proposed.\n","1. **Basic CNN**: This first approach consists of a basic CNN wiht only few layers (details can be found under ./models/cnn.yp). \n","2. **Advanced CNN**: The second model is a more elaborated CNN model, with multiple layers. \n","3. **Advanced CNN with Radius Informations**: In this approach, the same CNN as in point 2 has been used, but before the fully connected layer, the information of the radius has been inserted. \n","4. **Efficient-net**: A last approach is to use a pre-trained model. This model has been trained on ImageNet 1k.\n","\n","All the results can be found in the README.md file."]},{"cell_type":"markdown","metadata":{"id":"vioDjLedbIfB"},"source":["## 4.1 Create Dataloader"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":2057,"status":"ok","timestamp":1716203005807,"user":{"displayName":"Vincent Roduit","userId":"13076277421100865046"},"user_tz":-120},"id":"p6yY-omk97pV"},"outputs":[],"source":["train_dataloader, val_dataloader = create_dataloader(\n","    train_images=train_images_aug_resized,\n","    train_labels=train_images_labels_aug,\n","    train_radius=None,#train_radius_aug, #Set to None if not needed\n","    val_images=val_images_resized, #Set to None if not needed\n","    val_labels=val_images_labels,\n","    val_radius=None)#val_radius)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":1066,"status":"ok","timestamp":1716203011666,"user":{"displayName":"Vincent Roduit","userId":"13076277421100865046"},"user_tz":-120},"id":"w04lOlduhUNU"},"outputs":[],"source":["test_dataloader = create_test_dataloader(test_imgs, None)#test_radius_infos)"]},{"cell_type":"markdown","metadata":{"id":"sDXPXW5m97pV"},"source":["## 4.2 Custom Basic CNN"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":268,"status":"ok","timestamp":1716203013491,"user":{"displayName":"Vincent Roduit","userId":"13076277421100865046"},"user_tz":-120},"id":"0KJd1iJ9hNO7"},"outputs":[],"source":["image_dim = train_images_aug_resized.shape[1]\n","num_classes = len(conversion_table)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":76148,"status":"ok","timestamp":1716204622507,"user":{"displayName":"Vincent Roduit","userId":"13076277421100865046"},"user_tz":-120},"id":"lMOAB3wB97pV","outputId":"866bc36b-a37d-465f-a1c6-0b2b2f9c6aca"},"outputs":[],"source":["# Define the model\n","cnn = Basic_CNN(img_size=image_dim, num_classes=num_classes)\n","\n","# Define the optimizer\n","optimizer = torch.optim.Adam(cnn.parameters(), lr=0.001)\n","# Define the scheduler\n","scheduler = ReduceLROnPlateau(\n","    optimizer, mode=\"min\", factor=0.1, patience=2, verbose=True\n",")\n","\n","# Train the model\n","cnn.train_model(\n","    optimizer,\n","    scheduler,\n","    train_dataloader,\n","    val_dataloader,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jjvnCNS6ftGq"},"outputs":[],"source":["predictions = cnn.predict(test_dataloader)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cd07oK3kkh9F"},"outputs":[],"source":["df_submission = create_submission_file(predictions, df_test_images, conversion_table)"]},{"cell_type":"markdown","metadata":{"id":"gfKzrfvVbIfC"},"source":["## 4.3 Custom Advanced CNN"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":89506,"status":"ok","timestamp":1716204712010,"user":{"displayName":"Vincent Roduit","userId":"13076277421100865046"},"user_tz":-120},"id":"JWURUBI8bIfC","outputId":"470541a6-a48c-47f5-b222-52b047a5505d"},"outputs":[],"source":["# Define the model\n","cnn = Advanced_CNN(img_size=image_dim, num_classes=num_classes)\n","\n","# Define the optimizer\n","optimizer = torch.optim.Adam(cnn.parameters(), lr=0.001)\n","# Define the scheduler\n","scheduler = ReduceLROnPlateau(\n","    optimizer, mode=\"min\", factor=0.1, patience=2, verbose=True\n",")\n","\n","# Train the model\n","cnn.train_model(\n","    optimizer,\n","    scheduler,\n","    train_dataloader,\n","    val_dataloader,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":2285,"status":"ok","timestamp":1716205247712,"user":{"displayName":"Vincent Roduit","userId":"13076277421100865046"},"user_tz":-120},"id":"RbX_9sGpzb4D"},"outputs":[],"source":["predictions = cnn.predict(test_dataloader)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1716205375859,"user":{"displayName":"Vincent Roduit","userId":"13076277421100865046"},"user_tz":-120},"id":"tB5VcvqfzfSi"},"outputs":[],"source":["df_submission_advanced = create_submission_file(predictions, df_test_images, conversion_table, name='submission_advanced.csv')"]},{"cell_type":"markdown","metadata":{"id":"DwBrhANvbIfC"},"source":["## 4.3 Custom CNN with Radius Informations"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":146552,"status":"ok","timestamp":1716202596185,"user":{"displayName":"Vincent Roduit","userId":"13076277421100865046"},"user_tz":-120},"id":"8bRHr9CdbIfC","outputId":"759ad78e-8001-4c6b-e3aa-5c8e9a31321a"},"outputs":[],"source":["# Define the model\n","cnn = CnnRadius(img_size=image_dim, num_classes=num_classes)\n","\n","# Define the optimizer\n","optimizer = torch.optim.Adam(cnn.parameters(), lr=0.001)\n","# Define the scheduler\n","scheduler = ReduceLROnPlateau(\n","    optimizer, mode=\"min\", factor=0.1, patience=2, verbose=True\n",")\n","\n","# Train the model\n","cnn.train_model(\n","    optimizer,\n","    scheduler,\n","    train_dataloader,\n","    val_dataloader,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":2202,"status":"ok","timestamp":1716202720599,"user":{"displayName":"Vincent Roduit","userId":"13076277421100865046"},"user_tz":-120},"id":"lymJkN8npgr1"},"outputs":[],"source":["predictions = cnn.predict(test_dataloader)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":374,"status":"ok","timestamp":1716202735133,"user":{"displayName":"Vincent Roduit","userId":"13076277421100865046"},"user_tz":-120},"id":"OQO1GNbSp1c-"},"outputs":[],"source":["df_submission_radius = create_submission_file(predictions, df_test_images, conversion_table)"]},{"cell_type":"markdown","metadata":{"id":"6sscc9fm97pV"},"source":["## 4.4 EFFICIENT-NET"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["dataloaders = {\n","    'train': train_dataloader,\n","    'val': val_dataloader}\n","dataset_sizes = {x: len(dataloaders[x]) * constants.BATCH_SIZE for x in ['train', 'val']}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K8ocQLvN97pV"},"outputs":[],"source":["# 3. Load a pre-trained model and modify the final layer\n","model = timm.create_model('efficientnet_b0', pretrained=True, num_classes=num_classes)\n","\n","# 4. Define criterion, optimizer and scheduler\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n","\n","# 5. Training loop\n","def train_model(model, dataloaders, criterion, optimizer, scheduler, num_epochs=25):\n","    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","    model = model.to(device)\n","    \n","    for epoch in range(num_epochs):\n","        print(f'Epoch {epoch}/{num_epochs - 1}')\n","        print('-' * 10)\n","\n","        for phase in ['train', 'val']:\n","            if phase == 'train':\n","                model.train()  # Set model to training mode\n","            else:\n","                model.eval()   # Set model to evaluate mode\n","\n","            running_loss = 0.0\n","            running_corrects = 0\n","\n","            for inputs, labels in dataloaders[phase]:\n","                inputs = inputs.to(device)\n","                labels = labels.to(device)\n","\n","                optimizer.zero_grad()\n","\n","                with torch.set_grad_enabled(phase == 'train'):\n","                    outputs = model(inputs)\n","                    _, preds = torch.max(outputs, 1)\n","                    loss = criterion(outputs, labels)\n","\n","                    if phase == 'train':\n","                        loss.backward()\n","                        optimizer.step()\n","\n","                running_loss += loss.item() * inputs.size(0)\n","                running_corrects += torch.sum(preds == labels.data)\n","\n","            if phase == 'train':\n","                scheduler.step()\n","\n","            epoch_loss = running_loss / dataset_sizes[phase]\n","            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n","\n","            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n","\n","        print()\n","\n","    return model\n","\n","# Train the model\n","model = train_model(model, dataloaders, criterion, optimizer, scheduler, num_epochs=10)\n","\n","def predict(model, dataloader):\n","    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","    model = model.to(device)\n","    model.eval()\n","    predictions = []\n","\n","    for inputs, _ in dataloader:\n","        inputs = inputs.to(device)\n","        outputs = model(inputs)\n","        _, preds = torch.max(outputs, 1)\n","        predictions.extend(preds.cpu().numpy())\n","\n","    return predictions"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.3"}},"nbformat":4,"nbformat_minor":0}
