{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"O-nZ59Vf97pK"},"outputs":[],"source":["# -*- coding: utf-8 -*-\n","# -*- authors : Vincent Roduit, Filippo Quadri -*-\n","# -*- date : 2024-05-03 -*-\n","# -*- Last revision: 2024-05-03 -*-\n","# -*- python version : 3.9.18 -*-\n","# -*- Description: Notebook that summarize results-*-"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2075,"status":"ok","timestamp":1716199878873,"user":{"displayName":"Vincent Roduit","userId":"13076277421100865046"},"user_tz":-120},"id":"6941kpJ89_mu","outputId":"f45b5137-d56a-462a-8da2-48636e5cadaf"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content/drive/MyDrive/EE-451-IAPR/project/src\n"]}],"source":["#Prepare Google Colab Environment\n","from google.colab import drive\n","drive.mount('/content/drive')\n","%cd /content/drive/MyDrive/EE-451-IAPR/project/src"]},{"cell_type":"markdown","metadata":{"id":"ZGn195Dx97pN"},"source":["# <center> EE - 451 Image Analysis and Pattern recognition </center>\n","## <center> Ecole Polytechnique Fédérale de Lausanne </center>\n","### <center>Coin Challenge </center>\n","---"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":255,"status":"ok","timestamp":1716200700272,"user":{"displayName":"Vincent Roduit","userId":"13076277421100865046"},"user_tz":-120},"id":"7K7Y8PkC97pP"},"outputs":[],"source":["#Import libraries\n","import torch\n","import importlib\n","from torch.optim.lr_scheduler import ReduceLROnPlateau\n","from torch import nn\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":237,"status":"ok","timestamp":1716200725325,"user":{"displayName":"Vincent Roduit","userId":"13076277421100865046"},"user_tz":-120},"id":"UTG2yckF97pP","outputId":"92e5905c-acb4-45a1-96de-341217c4012c"},"outputs":[{"output_type":"stream","name":"stdout","text":["The autoreload extension is already loaded. To reload it, use:\n","  %reload_ext autoreload\n"]}],"source":["#Import files\n","import constants\n","importlib.reload(constants)\n","\n","#Classes\n","from data_classes.ref_data import refCoin\n","from data_classes.train_data import trainCoin\n","from data_classes.test_data import testCoin\n","\n","#Functions\n","from visualization import *\n","from pickle_func import *\n","from pre_processing.process_func import *\n","from pre_processing.data_augmentation import *\n","from post_processing.data_formating import *\n","from post_processing.dataloader import *\n","\n","#Models\n","from models.cnn import Basic_CNN, Advanced_CNN, CnnRadius\n","%load_ext autoreload\n","%autoreload 2\n"]},{"cell_type":"markdown","metadata":{"id":"_5wZnAr697pQ"},"source":["# 1. Load different Datasets"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-JGPRvL197pR","outputId":"937bba94-8957-47a3-e8a2-620ef6f82279"},"outputs":[{"name":"stdout","output_type":"stream","text":["Loading data from pickle files\n"]}],"source":["ref_data = refCoin(save=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"29XCNbx397pR","outputId":"76e21ae1-d069-4441-a913-425f826cae4d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Loading data from pickle files\n"]}],"source":["train_data = trainCoin(save=False, load_from_pickle=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"95YGqtKe97pS","outputId":"756b3f8d-e599-40c7-9f71-8b4e2aee2f1a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Loading data from pickle files\n"]}],"source":["test_data = testCoin(save=False)"]},{"cell_type":"markdown","metadata":{"id":"uaoCU_3M97pS"},"source":["# 2 Processing Data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZKWiHjoQ97pT","outputId":"b467915f-cc84-4905-d6f0-51807cd7d88f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Finding contours\n","Creating masked images\n","Creating coin images\n"]}],"source":["#Process all the images :\n","# 1. clean the images and find the contours\n","# 2. create the masked images\n","# 3. create the coin images\n","# 4. if save = True, save the images and the class in a result folder\n","train_data.proceed_data()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"O6eN8TorbrPp"},"outputs":[],"source":["ref_data.proceed_data()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MBHFQKtfbrPp","outputId":"b1baa5c3-a6a6-4a67-9a35-1ae74d4d2811"},"outputs":[{"name":"stdout","output_type":"stream","text":["Finding contours\n","Creating masked images\n","Creating coin images\n"]}],"source":["test_data.proceed_data()"]},{"cell_type":"markdown","metadata":{"id":"Qmr1XfI_bIe-"},"source":["## 3.1 Fetch the labels"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"d1FW4ji797pT","executionInfo":{"status":"ok","timestamp":1716199884570,"user_tz":-120,"elapsed":4,"user":{"displayName":"Vincent Roduit","userId":"13076277421100865046"}}},"outputs":[],"source":["conversion_table = get_classes_conv_table()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6s1vxbmk97pT"},"outputs":[],"source":["# Associate the labels to the coins\n","coin_labels = get_coin_labels()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GfKkLy3w97pU"},"outputs":[],"source":["# Extract the images and the labels + create a dataframe that summarize the data\n","train_images_raw,train_radius_infos, labels, df_train_images_labels = create_train_data_structure(train_data.coins, train_data.contours_tuple, coin_labels,conversion_table)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wXlaQh5FbrPq"},"outputs":[],"source":["test_imgs, test_radius_infos, df_test_images = create_test_data_structure(test_data.coins, test_data.contours_tuple)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UQOnhQU0brPq"},"outputs":[],"source":["save_pickle(test_imgs, 'test_imgs.pkl')\n","save_pickle(test_radius_infos, 'test_radius_infos.pkl')\n","save_pickle(df_test_images, 'df_test_images.pkl')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d5DSzvkP97pU"},"outputs":[],"source":["# Optional : save the coins in ../data/results/coins_classified\n","#           the coins are separated in folders according to their class\n","save_coins_classified(df_train_images_labels, train_images_raw)"]},{"cell_type":"markdown","metadata":{"id":"JJfDYX1kbIe_"},"source":["## 3.2 Data augmentation and train/validation split"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qhElOdHX97pU"},"outputs":[],"source":["# Create the splits (train and validation)\n","train_images, train_radius, train_labels, val_images, val_radius, val_labels = create_splits(train_images_raw, train_radius_infos, labels)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"z2MkspQE97pU"},"outputs":[],"source":["# Augment the training set with rotations\n","train_images_aug, train_radius_aug, train_labels_aug = augment_set_rotations(train_images, train_radius, train_labels)\n","\n","# Augment the training set with Gaussian blur\n","# train_images_aug, train_radius_aug, train_labels_aug = augment_blur(train_images_aug, train_labels_aug)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6k1nLFlbbIfA"},"outputs":[],"source":["#Optional : save the datasets in ../data/results/pickle_files\n","save_pickle(result=train_images_aug, file_name='train_images_aug_resized.pkl')\n","save_pickle(result=train_radius_aug, file_name='train_radius_aug.pkl')\n","save_pickle(result=train_labels_aug, file_name='train_labels_aug.pkl')\n","\n","save_pickle(result=val_images, file_name='val_images_resized.pkl')\n","save_pickle(result=val_radius, file_name='val_radius.pkl')\n","save_pickle(result=val_labels, file_name='val_labels.pkl')"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":3078,"status":"ok","timestamp":1716199896185,"user":{"displayName":"Vincent Roduit","userId":"13076277421100865046"},"user_tz":-120},"id":"6yY0F4U_-NU8"},"outputs":[],"source":["# Optional : Load precomputed data\n","train_images_aug_resized = load_pickle('train_images_aug_resized.pkl')\n","train_images_labels_aug = load_pickle('train_labels_aug.pkl')\n","train_radius_aug = load_pickle('train_radius_aug.pkl')\n","\n","val_images_resized = load_pickle('val_images_resized.pkl')\n","val_radius = load_pickle('val_radius.pkl')\n","val_images_labels = load_pickle('val_labels.pkl')\n","\n","test_imgs = load_pickle('test_imgs.pkl')\n","test_radius_infos = load_pickle('test_radius_infos.pkl')\n","df_test_images = load_pickle('df_test_images.pkl')"]},{"cell_type":"markdown","metadata":{"id":"jTOA14mK97pV"},"source":["# 4 Train Neural Network\n"]},{"cell_type":"markdown","metadata":{"id":"vioDjLedbIfB"},"source":["## 4.1 Create Dataloader"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":1562,"status":"ok","timestamp":1716199900516,"user":{"displayName":"Vincent Roduit","userId":"13076277421100865046"},"user_tz":-120},"id":"p6yY-omk97pV"},"outputs":[],"source":["train_dataloader, val_dataloader = create_dataloader(\n","    train_images=train_images_aug_resized,\n","    train_labels=train_images_labels_aug,\n","    train_radius=None,#train_radius_aug, #Set to None if not needed\n","    val_images=val_images_resized, #Set to None if not needed\n","    val_labels=val_images_labels,\n","    val_radius=None)#val_radius)"]},{"cell_type":"code","source":["test_dataloader = create_test_dataloader(test_imgs)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":180},"id":"w04lOlduhUNU","executionInfo":{"status":"error","timestamp":1716200737831,"user_tz":-120,"elapsed":292,"user":{"displayName":"Vincent Roduit","userId":"13076277421100865046"}},"outputId":"41c5ef24-ffc9-4580-c29f-c2ab8c8c60c6"},"execution_count":22,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'create_test_dataloader' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-22-cafaddacfc0f>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_dataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_test_dataloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_imgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'create_test_dataloader' is not defined"]}]},{"cell_type":"markdown","metadata":{"id":"sDXPXW5m97pV"},"source":["## 4.2 Custom Basic CNN"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1716199901957,"user":{"displayName":"Vincent Roduit","userId":"13076277421100865046"},"user_tz":-120},"id":"0KJd1iJ9hNO7"},"outputs":[],"source":["image_dim = train_images_aug_resized.shape[1]\n","num_classes = len(conversion_table)"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":78183,"status":"ok","timestamp":1716199983015,"user":{"displayName":"Vincent Roduit","userId":"13076277421100865046"},"user_tz":-120},"id":"lMOAB3wB97pV","outputId":"26c2e426-67dd-4a62-c224-852b7ae03fb8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10, Loss: 0.24353194430276945, Validation Accuracy: 0.8831\n","Epoch 2/10, Loss: 0.15734880253092035, Validation Accuracy: 0.9221\n","Epoch 3/10, Loss: 0.12066351922301503, Validation Accuracy: 0.9481\n","Epoch 4/10, Loss: 0.18461646739538615, Validation Accuracy: 0.9221\n","Epoch 5/10, Loss: 0.23576102318701805, Validation Accuracy: 0.9221\n","Epoch 6/10, Loss: 0.16414496070378787, Validation Accuracy: 0.9610\n","Epoch 7/10, Loss: 0.20330226034313054, Validation Accuracy: 0.9351\n","Epoch 8/10, Loss: 0.2049266370860013, Validation Accuracy: 0.9351\n","Epoch 9/10, Loss: 0.21719822713306972, Validation Accuracy: 0.9351\n","Epoch 10/10, Loss: 0.2091807591450679, Validation Accuracy: 0.9351\n"]}],"source":["# Define the model\n","cnn = Basic_CNN(img_size=image_dim, num_classes=num_classes)\n","\n","# Define the optimizer\n","optimizer = torch.optim.Adam(cnn.parameters(), lr=0.001)\n","# Define the scheduler\n","scheduler = ReduceLROnPlateau(\n","    optimizer, mode=\"min\", factor=0.1, patience=2, verbose=True\n",")\n","criterion = nn.BCEWithLogitsLoss()\n","\n","# Train the model\n","cnn.train_model(\n","    optimizer,\n","    scheduler,\n","    train_dataloader,\n","    val_dataloader,\n",")"]},{"cell_type":"code","source":["cnn.predict(test_imgs)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":323},"id":"jjvnCNS6ftGq","executionInfo":{"status":"error","timestamp":1716200160101,"user_tz":-120,"elapsed":319,"user":{"displayName":"Vincent Roduit","userId":"13076277421100865046"}},"outputId":"8e9b5254-0f28-4672-e5b1-574143788229"},"execution_count":9,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"'numpy.ndarray' object has no attribute 'to'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-0e8c73d5fae8>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_imgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/content/drive/MyDrive/EE-451-IAPR/project/src/models/cnn.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, test_loader)\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0minput\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m                 \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'to'"]}]},{"cell_type":"markdown","metadata":{"id":"gfKzrfvVbIfC"},"source":["## 4.3 Custom Advanced CNN"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JWURUBI8bIfC"},"outputs":[],"source":["# Define the model\n","cnn = Advanced_CNN(img_size=image_dim, num_classes=num_classes)\n","\n","# Define the optimizer\n","optimizer = torch.optim.Adam(cnn.parameters(), lr=0.001)\n","# Define the scheduler\n","scheduler = ReduceLROnPlateau(\n","    optimizer, mode=\"min\", factor=0.1, patience=2, verbose=True\n",")\n","criterion = nn.BCEWithLogitsLoss()\n","\n","# Train the model\n","cnn.train_model(\n","    optimizer,\n","    scheduler,\n","    train_dataloader,\n","    val_dataloader,\n",")"]},{"cell_type":"markdown","metadata":{"id":"DwBrhANvbIfC"},"source":["## 4.3 Custom CNN with Radius Informations"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8bRHr9CdbIfC"},"outputs":[],"source":["# Define the model\n","cnn = CnnRadius(img_size=image_dim, num_classes=num_classes)\n","\n","# Define the optimizer\n","optimizer = torch.optim.Adam(cnn.parameters(), lr=0.001)\n","# Define the scheduler\n","scheduler = ReduceLROnPlateau(\n","    optimizer, mode=\"min\", factor=0.1, patience=2, verbose=True\n",")\n","\n","# Train the model\n","cnn.train_model(\n","    optimizer,\n","    scheduler,\n","    train_dataloader,\n","    val_dataloader,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ks85aVLbbrPt"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"6sscc9fm97pV"},"source":["## 4.4 RESNET-50"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K8ocQLvN97pV"},"outputs":[],"source":["from transformers import AutoImageProcessor, ResNetForImageClassification\n","from torchvision import transforms\n","from datasets import load_metric\n","\n","# Step 2: Modify the final layer\n","model = ResNetForImageClassification.from_pretrained(\"microsoft/resnet-50\")\n","\n","# Replace the classifier\n","num_classes = 15\n","model.classifier = nn.Linear(model.classifier.in_features, num_classes)\n","\n","# Step 3: Fine-tune the model\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n","\n","# Training loop\n","for epoch in range(10):  # Adjust the number of epochs as needed\n","    model.train()\n","    for images, labels in train_dataloader:\n","        images, labels = images.to(device), labels.to(device)\n","\n","        optimizer.zero_grad()\n","        outputs = model(images).logits\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","    print(f\"Epoch {epoch+1}/{10}, Loss: {loss.item()}\")\n","\n","# Evaluation\n","model.eval()\n","metric = load_metric(\"accuracy\")\n","for images, labels in val_dataloader:\n","    images, labels = images.to(device), labels.to(device)\n","    with torch.no_grad():\n","        outputs = model(images).logits\n","    predictions = torch.argmax(outputs, dim=1)\n","    metric.add_batch(predictions=predictions, references=labels)\n","\n","accuracy = metric.compute()\n","print(f\"Test Accuracy: {accuracy['accuracy']:.4f}\")"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.3"}},"nbformat":4,"nbformat_minor":0}