{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"O-nZ59Vf97pK"},"outputs":[],"source":["# -*- coding: utf-8 -*-\n","# -*- authors : Vincent Roduit, Filippo Quadri -*-\n","# -*- date : 2024-05-03 -*-\n","# -*- Last revision: 2024-05-03 -*-\n","# -*- python version : 3.9.18 -*-\n","# -*- Description: Notebook that summarize results-*-"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21049,"status":"ok","timestamp":1716057774922,"user":{"displayName":"Vincent Roduit","userId":"13076277421100865046"},"user_tz":-120},"id":"6941kpJ89_mu","outputId":"7d8a01d3-fc1f-4101-9194-0e08c3cdbd30"},"outputs":[],"source":["#Prepare Google Colab Environment\n","from google.colab import drive\n","drive.mount('/content/drive')\n","%cd /content/drive/MyDrive/EE-451-IAPR/project/src"]},{"cell_type":"markdown","metadata":{"id":"ZGn195Dx97pN"},"source":["# <center> EE - 451 Image Analysis and Pattern recognition </center>\n","## <center> Ecole Polytechnique Fédérale de Lausanne </center>\n","### <center>Coin Challenge </center>\n","---"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":226,"status":"ok","timestamp":1716058944926,"user":{"displayName":"Vincent Roduit","userId":"13076277421100865046"},"user_tz":-120},"id":"7K7Y8PkC97pP"},"outputs":[],"source":["#Import libraries\n","import torch\n","import importlib\n","from torch.optim.lr_scheduler import ReduceLROnPlateau\n","from torch import nn\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1268,"status":"ok","timestamp":1716059220033,"user":{"displayName":"Vincent Roduit","userId":"13076277421100865046"},"user_tz":-120},"id":"UTG2yckF97pP","outputId":"af7ee204-14ad-4694-ac84-ea424c93b40c"},"outputs":[],"source":["#Import files\n","import constants\n","importlib.reload(constants)\n","\n","#Classes\n","from data_classes.ref_data import refCoin\n","from data_classes.train_data import trainCoin\n","from data_classes.test_data import testCoin\n","\n","#Functions\n","from visualization import *\n","from pickle_func import *\n","from pre_processing.process_func import *\n","from pre_processing.data_augmentation import *\n","from post_processing.data_formating import *\n","from post_processing.dataloader import *\n","\n","#Models\n","from models.cnn import Basic_CNN, Advanced_CNN, CnnRadius\n","%load_ext autoreload\n","%autoreload 2\n"]},{"cell_type":"markdown","metadata":{"id":"_5wZnAr697pQ"},"source":["# 1. Load different Datasets"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"-JGPRvL197pR"},"outputs":[{"name":"stdout","output_type":"stream","text":["Loading data from pickle files\n"]}],"source":["ref_data = refCoin(save=False)"]},{"cell_type":"code","execution_count":38,"metadata":{"id":"29XCNbx397pR","outputId":"76e21ae1-d069-4441-a913-425f826cae4d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Loading data from pickle files\n"]}],"source":["train_data = trainCoin(save=False, load_from_pickle=False)"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"95YGqtKe97pS","outputId":"756b3f8d-e599-40c7-9f71-8b4e2aee2f1a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Loading data from pickle files\n"]}],"source":["test_data = testCoin(save=False)"]},{"cell_type":"markdown","metadata":{"id":"uaoCU_3M97pS"},"source":["# 2 Processing Data"]},{"cell_type":"code","execution_count":39,"metadata":{"id":"ZKWiHjoQ97pT","outputId":"b467915f-cc84-4905-d6f0-51807cd7d88f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Finding contours\n","Creating masked images\n","Creating coin images\n"]}],"source":["#Process all the images :\n","# 1. clean the images and find the contours\n","# 2. create the masked images\n","# 3. create the coin images\n","# 4. if save = True, save the images and the class in a result folder\n","train_data.proceed_data()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["ref_data.proceed_data()"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Finding contours\n","Creating masked images\n","Creating coin images\n"]}],"source":["test_data.proceed_data()"]},{"cell_type":"markdown","metadata":{"id":"Qmr1XfI_bIe-"},"source":["## 3.1 Fetch the labels"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":410,"status":"ok","timestamp":1716057810525,"user":{"displayName":"Vincent Roduit","userId":"13076277421100865046"},"user_tz":-120},"id":"d1FW4ji797pT"},"outputs":[],"source":["conversion_table = get_classes_conv_table()"]},{"cell_type":"code","execution_count":50,"metadata":{"id":"6s1vxbmk97pT"},"outputs":[],"source":["# Associate the labels to the coins\n","coin_labels = get_coin_labels()"]},{"cell_type":"code","execution_count":51,"metadata":{"id":"GfKkLy3w97pU"},"outputs":[],"source":["# Extract the images and the labels + create a dataframe that summarize the data\n","train_images_raw,train_radius_infos, labels, df_train_images_labels = create_train_data_structure(train_data.coins, train_data.contours_tuple, coin_labels,conversion_table)"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["test_imgs, test_radius_infos, df_test_images = create_test_data_structure(test_data.coins, test_data.contours_tuple)"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["save_pickle(test_imgs, 'test_imgs.pkl')\n","save_pickle(test_radius_infos, 'test_radius_infos.pkl')\n","save_pickle(df_test_images, 'df_test_images.pkl')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d5DSzvkP97pU"},"outputs":[],"source":["# Optional : save the coins in ../data/results/coins_classified\n","#           the coins are separated in folders according to their class\n","save_coins_classified(df_train_images_labels, train_images_raw)"]},{"cell_type":"markdown","metadata":{"id":"JJfDYX1kbIe_"},"source":["## 3.2 Data augmentation and train/validation split"]},{"cell_type":"code","execution_count":33,"metadata":{"id":"qhElOdHX97pU"},"outputs":[],"source":["# Create the splits (train and validation)\n","train_images, train_radius, train_labels, val_images, val_radius, val_labels = create_splits(train_images_raw, train_radius_infos, labels)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"z2MkspQE97pU"},"outputs":[],"source":["# Augment the training set with rotations\n","train_images_aug, train_radius_aug, train_labels_aug = augment_set_rotations(train_images, train_radius, train_labels)\n","\n","# Augment the training set with Gaussian blur\n","# train_images_aug, train_radius_aug, train_labels_aug = augment_blur(train_images_aug, train_labels_aug)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6k1nLFlbbIfA"},"outputs":[],"source":["#Optional : save the datasets in ../data/results/pickle_files\n","save_pickle(result=train_images_aug, file_name='train_images_aug_resized.pkl')\n","save_pickle(result=train_radius_aug, file_name='train_radius_aug.pkl')\n","save_pickle(result=train_labels_aug, file_name='train_labels_aug.pkl')\n","\n","save_pickle(result=val_images, file_name='val_images_resized.pkl')\n","save_pickle(result=val_radius, file_name='val_radius.pkl')\n","save_pickle(result=val_labels, file_name='val_labels.pkl')"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":2019,"status":"ok","timestamp":1716059171638,"user":{"displayName":"Vincent Roduit","userId":"13076277421100865046"},"user_tz":-120},"id":"6yY0F4U_-NU8"},"outputs":[],"source":["# Optional : Load precomputed data\n","train_images_aug_resized = load_pickle('train_images_aug_resized.pkl')\n","train_images_labels_aug = load_pickle('train_labels_aug.pkl')\n","train_radius_aug = load_pickle('train_radius_aug.pkl')\n","\n","val_images_resized = load_pickle('val_images_resized.pkl')\n","val_radius = load_pickle('val_radius.pkl')\n","val_images_labels = load_pickle('val_labels.pkl')"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["test_imgs = load_pickle('test_imgs.pkl')\n","test_radius_infos = load_pickle('test_radius_infos.pkl')\n","df_test_images = load_pickle('df_test_images.pkl')"]},{"cell_type":"markdown","metadata":{"id":"jTOA14mK97pV"},"source":["# 4 Train Neural Network\n"]},{"cell_type":"markdown","metadata":{"id":"vioDjLedbIfB"},"source":["## 4.1 Create Dataloader"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":4881,"status":"ok","timestamp":1716059218767,"user":{"displayName":"Vincent Roduit","userId":"13076277421100865046"},"user_tz":-120},"id":"p6yY-omk97pV"},"outputs":[],"source":["train_dataloader, val_dataloader = create_dataloader(\n","    train_images=train_images_aug_resized,\n","    train_labels=train_images_labels_aug,\n","    train_radius=train_radius_aug, #Set to None if not needed\n","    val_images=val_images_resized, #Set to None if not needed\n","    val_labels=val_images_labels,\n","    val_radius=val_radius)"]},{"cell_type":"markdown","metadata":{"id":"sDXPXW5m97pV"},"source":["## 4.2 Custom Basic CNN"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":246,"status":"ok","timestamp":1716058969577,"user":{"displayName":"Vincent Roduit","userId":"13076277421100865046"},"user_tz":-120},"id":"0KJd1iJ9hNO7"},"outputs":[],"source":["image_dim = train_images_aug_resized.shape[1]\n","num_classes = len(conversion_table)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":228125,"status":"ok","timestamp":1716025223130,"user":{"displayName":"Vincent Roduit","userId":"13076277421100865046"},"user_tz":-120},"id":"lMOAB3wB97pV","outputId":"50fba308-e131-4dbe-cf2f-c23736b84134"},"outputs":[],"source":["# Define the model\n","cnn = Basic_CNN(img_size=image_dim, num_classes=num_classes)\n","\n","# Define the optimizer\n","optimizer = torch.optim.Adam(cnn.parameters(), lr=0.001)\n","# Define the scheduler\n","scheduler = ReduceLROnPlateau(\n","    optimizer, mode=\"min\", factor=0.1, patience=2, verbose=True\n",")\n","criterion = nn.BCEWithLogitsLoss()\n","\n","# Train the model\n","cnn.train_model(\n","    optimizer,\n","    scheduler,\n","    train_dataloader,\n","    val_dataloader,\n",")"]},{"cell_type":"markdown","metadata":{"id":"gfKzrfvVbIfC"},"source":["## 4.3 Custom Advanced CNN"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JWURUBI8bIfC"},"outputs":[],"source":["# Define the model\n","cnn = Advanced_CNN(img_size=image_dim, num_classes=num_classes)\n","\n","# Define the optimizer\n","optimizer = torch.optim.Adam(cnn.parameters(), lr=0.001)\n","# Define the scheduler\n","scheduler = ReduceLROnPlateau(\n","    optimizer, mode=\"min\", factor=0.1, patience=2, verbose=True\n",")\n","criterion = nn.BCEWithLogitsLoss()\n","\n","# Train the model\n","cnn.train_model(\n","    optimizer,\n","    scheduler,\n","    train_dataloader,\n","    val_dataloader,\n",")"]},{"cell_type":"markdown","metadata":{"id":"DwBrhANvbIfC"},"source":["## 4.3 Custom CNN with Radius Informations"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":153292,"status":"ok","timestamp":1716059378081,"user":{"displayName":"Vincent Roduit","userId":"13076277421100865046"},"user_tz":-120},"id":"8bRHr9CdbIfC","outputId":"91746c27-c46b-4464-973c-ccfcc7a70614"},"outputs":[],"source":["# Define the model\n","cnn = CnnRadius(img_size=image_dim, num_classes=num_classes)\n","\n","# Define the optimizer\n","optimizer = torch.optim.Adam(cnn.parameters(), lr=0.001)\n","# Define the scheduler\n","scheduler = ReduceLROnPlateau(\n","    optimizer, mode=\"min\", factor=0.1, patience=2, verbose=True\n",")\n","\n","# Train the model\n","cnn.train_model(\n","    optimizer,\n","    scheduler,\n","    train_dataloader,\n","    val_dataloader,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"6sscc9fm97pV"},"source":["## 4.4 RESNET-50"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K8ocQLvN97pV"},"outputs":[],"source":["from transformers import AutoImageProcessor, ResNetForImageClassification\n","from torchvision import transforms\n","from datasets import load_metric\n","\n","# Step 2: Modify the final layer\n","model = ResNetForImageClassification.from_pretrained(\"microsoft/resnet-50\")\n","\n","# Replace the classifier\n","num_classes = 15\n","model.classifier = nn.Linear(model.classifier.in_features, num_classes)\n","\n","# Step 3: Fine-tune the model\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n","\n","# Training loop\n","for epoch in range(10):  # Adjust the number of epochs as needed\n","    model.train()\n","    for images, labels in train_dataloader:\n","        images, labels = images.to(device), labels.to(device)\n","\n","        optimizer.zero_grad()\n","        outputs = model(images).logits\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","    print(f\"Epoch {epoch+1}/{10}, Loss: {loss.item()}\")\n","\n","# Evaluation\n","model.eval()\n","metric = load_metric(\"accuracy\")\n","for images, labels in val_dataloader:\n","    images, labels = images.to(device), labels.to(device)\n","    with torch.no_grad():\n","        outputs = model(images).logits\n","    predictions = torch.argmax(outputs, dim=1)\n","    metric.add_batch(predictions=predictions, references=labels)\n","\n","accuracy = metric.compute()\n","print(f\"Test Accuracy: {accuracy['accuracy']:.4f}\")"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.3"}},"nbformat":4,"nbformat_minor":0}
