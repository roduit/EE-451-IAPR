{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fourier Descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all the necessary libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import importlib\n",
    "import skimage as sk\n",
    "from skimage.color import rgb2hsv\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Callable\n",
    "import cv2 as cv\n",
    "from skimage.morphology import closing, opening, disk, remove_small_holes, remove_small_objects\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pickle(file_name, load_path):\n",
    "    \"\"\"Load a variable from a binary format path\n",
    "\n",
    "    Args:\n",
    "        file_path: the file path where the file is stored\n",
    "\n",
    "    Returns:\n",
    "        return the content of the file, generally a dataFrame here.\n",
    "    \"\"\"\n",
    "    file_path = os.path.join(load_path, file_name)\n",
    "    with open(file_path, \"rb\") as file:\n",
    "        return pickle.load(file)\n",
    "    \n",
    "images = load_pickle(\"coins.pkl\", \"../data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_gray(image):\n",
    "    \"\"\"Convert an image to gray\n",
    "\n",
    "    Args:\n",
    "        image: the image to convert\n",
    "\n",
    "    Returns:\n",
    "        return the converted image\n",
    "    \"\"\"\n",
    "    return cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "def find_contour(images: np.ndarray):\n",
    "    \"\"\"\n",
    "    Find the contours for the set of images\n",
    "    \n",
    "    Args\n",
    "    ----\n",
    "    images: np.ndarray (N, 28, 28)\n",
    "        Source images to process\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    contours: list of np.ndarray\n",
    "        List of N arrays containing the coordinates of the contour. Each element of the \n",
    "        list is an array of 2d coordinates (K, 2) where K depends on the number of elements \n",
    "        that form the contour. \n",
    "    \"\"\"\n",
    "\n",
    "    # Get number of images to process\n",
    "    N, _, _ = np.shape(images)\n",
    "    # Fill in dummy values (fake points)\n",
    "    contours = [np.array([[0, 0], [1, 1]]) for i in range(N)]\n",
    "\n",
    "    # ------------------\n",
    "    # Your code here ... \n",
    "    for idx, i in enumerate(images):\n",
    "        cnts = sk.measure.find_contours(np.transpose(i), fully_connected='high')[0]\n",
    "        contours[idx] = cnts\n",
    "    # ------------------\n",
    "    \n",
    "    return contours\n",
    "    \n",
    "def linear_interpolation(contours: np.ndarray, n_samples: int = 11):\n",
    "    \"\"\"\n",
    "    Perform interpolation/resampling of the contour across n_samples.\n",
    "    \n",
    "    Args\n",
    "    ----\n",
    "    contours: list of np.ndarray\n",
    "        List of N arrays containing the coordinates of the contour. Each element of the \n",
    "        list is an array of 2d coordinates (K, 2) where K depends on the number of elements \n",
    "        that form the contour. \n",
    "    n_samples: int\n",
    "        Number of samples to consider along the contour.\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    contours_inter: np.ndarray (N, n_samples, 2)\n",
    "        Interpolated contour with n_samples\n",
    "    \"\"\"\n",
    "\n",
    "    N = len(contours)\n",
    "    contours_inter = np.zeros((N, n_samples, 2))\n",
    "    \n",
    "    # ------------------\n",
    "    # Your code here ... \n",
    "    for idx, cnt in enumerate(contours):\n",
    "        differences = np.diff(cnt, axis=0)\n",
    "        distances = np.sqrt(np.sum(differences**2, axis=1))\n",
    "        cumulative_distances = np.concatenate([[0], np.cumsum(distances)])\n",
    "\n",
    "        # Interpolate the x and y coordinates\n",
    "        t = np.linspace(0, cumulative_distances[-1], n_samples + 1)\n",
    "        t = t[:-1]\n",
    "        x = np.interp(t, cumulative_distances, cnt[:, 0])\n",
    "        y = np.interp(t, cumulative_distances, cnt[:, 1])\n",
    "        contours_inter[idx] = np.stack([x, y], axis=1)\n",
    "    # ------------------\n",
    "        \n",
    "    return contours_inter\n",
    "\n",
    "def compute_descriptor_padding(contours: np.ndarray, n_samples: int = 11):\n",
    "    \"\"\"\n",
    "    Compute Fourier descriptors of input images\n",
    "    \n",
    "    Args\n",
    "    ----\n",
    "    contours: list of np.ndarray\n",
    "        List of N arrays containing the coordinates of the contour. Each element of the \n",
    "        list is an array of 2d coordinates (K, 2) where K depends on the number of elements \n",
    "        that form the contour. \n",
    "    n_samples: int\n",
    "        Number of samples to consider. If the contour length is higher, discard the remaining part. If it is shorter, add padding.\n",
    "        Make sure that the first element of the descriptor represents the continuous component.\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    descriptors: np.ndarray complex (N, n_samples)\n",
    "        Computed complex Fourier descriptors for the given input images\n",
    "    \"\"\"\n",
    "\n",
    "    N = len(contours)\n",
    "    # Look for the number of contours\n",
    "    descriptors = np.zeros((N, n_samples), dtype=np.complex_)\n",
    "\n",
    "    # ------------------\n",
    "    # Your code here ... \n",
    "    descriptors = np.array([np.fft.fft(contours[i][:, 0] + 1j * contours[i][:, 1], n_samples) for i in range(N)])\n",
    "    # ------------------\n",
    "\n",
    "    return descriptors\n",
    "\n",
    "def plot_features(features_a: np.ndarray, features_b: np.ndarray, label_a: str, label_b: str, title: str):\n",
    "    \"\"\"\n",
    "    Plot feature components a and b.\n",
    "    \n",
    "    Args\n",
    "    ----\n",
    "    features_a: np.ndarray (N, D)\n",
    "        Feature a with N samples and D complex features. \n",
    "    features_b: np.ndarray (N, D)\n",
    "        Feature b with N samples and D complex features.\n",
    "    label_a: str\n",
    "        Name of the feature a.\n",
    "    label_b: str\n",
    "        Name of the feature b.\n",
    "    \"\"\"\n",
    "\n",
    "    # Number of paris to display\n",
    "    n_features = features_a.shape[1]\n",
    "    # Define pairs for 2D plots\n",
    "    pairs = np.array(range(2*np.ceil(n_features / 2).astype(int)))\n",
    "    # Check if odd lenght, shift second feature to have pairs\n",
    "    if n_features % 2 == 1:\n",
    "        pairs[2:] = pairs[1:-1]\n",
    "    # Convert to 2d array\n",
    "    pairs = pairs.reshape(-1, 2)\n",
    "\n",
    "    # Plot each pairs and labels\n",
    "    n_plots = len(pairs)\n",
    "    _, axes = plt.subplots(3, n_plots, figsize=(15, 8))\n",
    "    \n",
    "    for i, (pa, pb) in enumerate(pairs):\n",
    "        # Real\n",
    "        axes[0, i].scatter(np.real(features_a[:, pa]), np.real(features_a[:, pb]), label=label_a, s=10, alpha=0.1)\n",
    "        axes[0, i].scatter(np.real(features_b[:, pa]), np.real(features_b[:, pb]), label=label_b, s=10, alpha=0.1)\n",
    "        axes[0, i].set_xlabel(\"Component {}\".format(pa))\n",
    "        axes[0, i].set_ylabel(\"Component {}\".format(pb))\n",
    "        axes[0, i].set_title(\"Real {} vs {}\".format(pa, pb))\n",
    "        axes[0, i].legend()\n",
    "        # Imag\n",
    "        axes[1, i].scatter(np.imag(features_a[:, pa]), np.imag(features_a[:, pb]), label=label_a, s=10, alpha=0.1)\n",
    "        axes[1, i].scatter(np.imag(features_b[:, pa]), np.imag(features_b[:, pb]), label=label_b, s=10, alpha=0.1)\n",
    "        axes[1, i].set_xlabel(\"Component {}\".format(pa))\n",
    "        axes[1, i].set_ylabel(\"Component {}\".format(pb))\n",
    "        axes[1, i].set_title(\"Imag. {} vs {}\".format(pa, pb))\n",
    "        axes[1, i].legend()\n",
    "        # Abs\n",
    "        axes[2, i].scatter(np.abs(features_a[:, pa]), np.abs(features_a[:, pb]), label=label_a, s=10, alpha=0.1)\n",
    "        axes[2, i].scatter(np.abs(features_b[:, pa]), np.abs(features_b[:, pb]), label=label_b, s=10, alpha=0.1)\n",
    "        axes[2, i].set_xlabel(\"Component {}\".format(pa))\n",
    "        axes[2, i].set_ylabel(\"Component {}\".format(pb))\n",
    "        axes[2, i].set_title(\"Abs. {} vs {}\".format(pa, pb))\n",
    "        axes[2, i].legend()\n",
    "\n",
    "    plt.suptitle(title)\n",
    "    plt.tight_layout()\n",
    "\n",
    "def resize_images(images, size):\n",
    "    \"\"\"Resize the images\n",
    "    Args:\n",
    "        images (list): list of images\n",
    "        size (tuple): size of the images\n",
    "    Returns:\n",
    "\n",
    "        np.array: resized images\n",
    "    \"\"\"\n",
    "    resized_images = [cv.resize(image, (size,size)) for image in images]\n",
    "    return np.array(resized_images)\n",
    "\n",
    "def pad_images(images):\n",
    "    \"\"\"Pad the images to the biggest image\n",
    "    Args:\n",
    "        images (list): list of images\n",
    "    \n",
    "    Returns:\n",
    "        images_padded : list of padded images\n",
    "    \"\"\"\n",
    "\n",
    "    # Find the dimensions of the biggest image\n",
    "    biggest_dim = max(max(image.shape[:2]) for image in images)\n",
    "    images_padded = []\n",
    "    for img in images:\n",
    "        # Calculate padding dimensions\n",
    "        height, width = img.shape[:2]\n",
    "        pad_height = biggest_dim - height\n",
    "        pad_width = biggest_dim - width\n",
    "\n",
    "        # Distribute padding evenly on both sides of the image\n",
    "        pad_top = pad_height // 2\n",
    "        pad_bottom = pad_height - pad_top\n",
    "        pad_left = pad_width // 2\n",
    "        pad_right = pad_width - pad_left\n",
    "\n",
    "        # Pad image with black\n",
    "        img_padded = cv.copyMakeBorder(img, pad_top, pad_bottom, pad_left, pad_right, cv.BORDER_CONSTANT, value=[0, 0, 0])\n",
    "        images_padded.append(img_padded)\n",
    "    \n",
    "    return images_padded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# images groups and convert to dict\u001b[39;00m\n\u001b[1;32m      4\u001b[0m image_group_1 \u001b[38;5;241m=\u001b[39m images[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m10\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mimages\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m)\n\u001b[1;32m      6\u001b[0m image_group_2 \u001b[38;5;241m=\u001b[39m images[\u001b[38;5;241m10\u001b[39m:\u001b[38;5;241m20\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# pad images\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "N_SAMPLES = 11\n",
    "\n",
    "# images groups and convert to dict\n",
    "image_group_1 = []\n",
    "image_group_2 = []\n",
    "\n",
    "# pad images\n",
    "image_group_1_padded = pad_images(image_group_1)\n",
    "image_group_2_padded = pad_images(image_group_2)\n",
    "\n",
    "# resize images\n",
    "image_group_1_resized = resize_images(image_group_1_padded, 300)\n",
    "image_group_2_resized = resize_images(image_group_2_padded, 300)\n",
    "\n",
    "print(image_group_1_resized[0].shape)\n",
    "\n",
    "# convert images to gray\n",
    "image_group_1_gray = [convert_gray(image) for image in image_group_1_resized]\n",
    "image_group_2_gray = [convert_gray(image) for image in image_group_2_resized]\n",
    "\n",
    "# find contours\n",
    "contours_group_1 = find_contour(image_group_1_gray)\n",
    "contours_group_2 = find_contour(image_group_2_gray)\n",
    "\n",
    "# interpolate contours\n",
    "contours_inter_group_1 = linear_interpolation(contours_group_1, N_SAMPLES)\n",
    "contours_inter_group_2 = linear_interpolation(contours_group_2, N_SAMPLES)\n",
    "\n",
    "# compute descriptors\n",
    "descriptors_group_1 = compute_descriptor_padding(contours_inter_group_1, N_SAMPLES)\n",
    "descriptors_group_2 = compute_descriptor_padding(contours_inter_group_2, N_SAMPLES)\n",
    "\n",
    "# plot features\n",
    "plot_features(descriptors_group_1, descriptors_group_2, \"Group 1\", \"Group 2\", \"Fourier descriptors\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iapr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
