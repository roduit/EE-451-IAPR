{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"O-nZ59Vf97pK"},"outputs":[],"source":["# -*- coding: utf-8 -*-\n","# -*- authors : Vincent Roduit, Filippo Quadri -*-\n","# -*- date : 2024-05-03 -*-\n","# -*- Last revision: 2024-05-03 -*-\n","# -*- python version : 3.9.18 -*-\n","# -*- Description: Notebook that summarize results-*-"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6941kpJ89_mu","executionInfo":{"status":"ok","timestamp":1716024865892,"user_tz":-120,"elapsed":17512,"user":{"displayName":"Vincent Roduit","userId":"13076277421100865046"}},"outputId":"3fb2c591-74ba-4294-b7ab-5ff4ad775c79"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/EE-451-IAPR/project/src"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AxyaHBd7-JkH","executionInfo":{"status":"ok","timestamp":1716024866265,"user_tz":-120,"elapsed":376,"user":{"displayName":"Vincent Roduit","userId":"13076277421100865046"}},"outputId":"e9266163-cc92-4499-ce4f-25d639b1d872"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/EE-451-IAPR/project/src\n"]}]},{"cell_type":"markdown","metadata":{"id":"ZGn195Dx97pN"},"source":["# <center> EE - 451 Image Analysis and Pattern recognition </center>\n","## <center> Ecole Polytechnique Fédérale de Lausanne </center>\n","### <center>Coin Challenge </center>\n","---"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"7K7Y8PkC97pP","executionInfo":{"status":"ok","timestamp":1716024974302,"user_tz":-120,"elapsed":255,"user":{"displayName":"Vincent Roduit","userId":"13076277421100865046"}}},"outputs":[],"source":["#Import libraries\n","import torch\n","import importlib\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UTG2yckF97pP","executionInfo":{"status":"ok","timestamp":1716024976335,"user_tz":-120,"elapsed":409,"user":{"displayName":"Vincent Roduit","userId":"13076277421100865046"}},"outputId":"f1996719-29e2-4bed-9dc2-c18cb9d11c94"},"outputs":[{"output_type":"stream","name":"stdout","text":["The autoreload extension is already loaded. To reload it, use:\n","  %reload_ext autoreload\n"]}],"source":["#Import files\n","from data_classes.ref_data import refCoin\n","from data_classes.train_data import trainCoin\n","from data_classes.test_data import testCoin\n","import constants\n","from visualization import *\n","from pickle_func import *\n","importlib.reload(constants)\n","from processing.process_func import *\n","from models.utils import *\n","from processing.data_augmentation import *\n","%load_ext autoreload\n","%autoreload 2"]},{"cell_type":"markdown","metadata":{"id":"_5wZnAr697pQ"},"source":["# 1. Load different Datasets"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-JGPRvL197pR"},"outputs":[],"source":["ref_data = refCoin()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"29XCNbx397pR","outputId":"76e21ae1-d069-4441-a913-425f826cae4d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Loading data from pickle files\n"]}],"source":["train_data = trainCoin(save=False, load_from_pickle=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"95YGqtKe97pS","outputId":"756b3f8d-e599-40c7-9f71-8b4e2aee2f1a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Loading data from pickle files\n"]}],"source":["test_data = testCoin()"]},{"cell_type":"markdown","metadata":{"id":"uaoCU_3M97pS"},"source":["# 2 Create Data Ready for Neural Network"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZKWiHjoQ97pT","outputId":"b467915f-cc84-4905-d6f0-51807cd7d88f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Finding contours\n","Creating masked images\n","Creating coin images\n"]}],"source":["#Process all the images :\n","# 1. clean the images and find the contours\n","# 2. create the masked images\n","# 3. create the coin images\n","# 4. if save = True, save the images and the class in a result folder\n","train_data.proceed_data()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F4DVOPuh97pT"},"outputs":[],"source":["save_pickle(train_data.coins, 'coins.pkl')\n","save_pickle(train_data.contours, 'contours.pkl')"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"d1FW4ji797pT","executionInfo":{"status":"ok","timestamp":1716024984621,"user_tz":-120,"elapsed":248,"user":{"displayName":"Vincent Roduit","userId":"13076277421100865046"}}},"outputs":[],"source":["conversion_table = get_classes_conv_table()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6s1vxbmk97pT"},"outputs":[],"source":["# Associate the labels to the coins\n","coin_labels = get_coin_labels()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GfKkLy3w97pU"},"outputs":[],"source":["# Extract the images and the labels + create a dataframe that summarize the data\n","images, labels, df_images_labels = create_data_structure(train_data.coins, train_data.contours, coin_labels, conversion_table)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d5DSzvkP97pU"},"outputs":[],"source":["save_coins_classified(df_images_labels, images)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qhElOdHX97pU"},"outputs":[],"source":["train_images, train_labels, val_images, val_labels = create_splits(images, labels)"]},{"cell_type":"markdown","metadata":{"id":"7QpfVmqV97pU"},"source":["# 3 Data Augmentation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"z2MkspQE97pU"},"outputs":[],"source":["train_images_aug, train_labels_aug = augment_set(train_images, train_labels)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N1Q1zmdE97pU"},"outputs":[],"source":["train_images_aug, train_labels_aug = augment_blur(train_images_aug, train_labels_aug)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xwsiBp5n97pU"},"outputs":[],"source":["train_images_aug_resized = resize_images(train_images_aug, 200)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Yp9lld_L97pU"},"outputs":[],"source":["save_pickle(train_images_aug_resized, 'train_images_aug_resized.pkl')"]},{"cell_type":"code","source":["train_images_aug_resized = load_pickle('train_images_aug_resized.pkl')\n","train_images_labels_aug = load_pickle('train_labels_aug.pkl')\n","\n","val_images_resized = load_pickle('val_images_resized.pkl')\n","val_images_labels = load_pickle('val_labels.pkl')"],"metadata":{"id":"6yY0F4U_-NU8","executionInfo":{"status":"ok","timestamp":1716024988305,"user_tz":-120,"elapsed":1141,"user":{"displayName":"Vincent Roduit","userId":"13076277421100865046"}}},"execution_count":13,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jTOA14mK97pV"},"source":["# 4 Train Neural Network\n"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"p6yY-omk97pV","executionInfo":{"status":"ok","timestamp":1716024992675,"user_tz":-120,"elapsed":2900,"user":{"displayName":"Vincent Roduit","userId":"13076277421100865046"}}},"outputs":[],"source":["train_dataloader, val_dataloader = create_dataloader(\n","    train_images_aug_resized,\n","    train_images_labels_aug,\n","    val_images_resized,\n","    val_images_labels)"]},{"cell_type":"markdown","metadata":{"id":"sDXPXW5m97pV"},"source":["## 4.1 Custom Basic CNN"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lMOAB3wB97pV","executionInfo":{"status":"ok","timestamp":1716025223130,"user_tz":-120,"elapsed":228125,"user":{"displayName":"Vincent Roduit","userId":"13076277421100865046"}},"outputId":"50fba308-e131-4dbe-cf2f-c23736b84134"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10, Loss: 2.2964949739092395, Validation Accuracy: 0.6883\n","Epoch 2/10, Loss: 1.718103261017106, Validation Accuracy: 0.7403\n","Epoch 3/10, Loss: 0.7807000739371538, Validation Accuracy: 0.9221\n","Epoch 4/10, Loss: 2.0474204140315675, Validation Accuracy: 0.8442\n","Epoch 5/10, Loss: 2.791350682638119, Validation Accuracy: 0.7922\n","Epoch 6/10, Loss: 6.755259082910292, Validation Accuracy: 0.7532\n","Epoch 7/10, Loss: 4.072394247674139, Validation Accuracy: 0.8182\n","Epoch 8/10, Loss: 4.198189846734584, Validation Accuracy: 0.8052\n","Epoch 9/10, Loss: 4.379997418846135, Validation Accuracy: 0.7922\n","Epoch 10/10, Loss: 4.464120910213626, Validation Accuracy: 0.7922\n"]}],"source":["from models.cnn import Basic_CNN\n","from torch.optim.lr_scheduler import ReduceLROnPlateau\n","from torch import nn\n","\n","image_dim = train_images_aug_resized.shape[1]\n","num_classes = len(conversion_table)\n","# Define the model\n","cnn = Basic_CNN(image_size=image_dim, num_classes=num_classes)\n","\n","# Define the optimizer\n","optimizer = torch.optim.Adam(cnn.parameters(), lr=0.001)\n","# Define the scheduler\n","scheduler = ReduceLROnPlateau(\n","    optimizer, mode=\"min\", factor=0.1, patience=2, verbose=True\n",")\n","criterion = nn.BCEWithLogitsLoss()\n","\n","# Train the model\n","cnn.train_model(\n","    optimizer,\n","    scheduler,\n","    train_dataloader,\n","    val_dataloader,\n",")"]},{"cell_type":"markdown","metadata":{"id":"6sscc9fm97pV"},"source":["# 4.2 RESNET-50"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K8ocQLvN97pV"},"outputs":[],"source":["from transformers import AutoImageProcessor, ResNetForImageClassification\n","from torchvision import transforms\n","from datasets import load_metric\n","\n","# Step 2: Modify the final layer\n","model = ResNetForImageClassification.from_pretrained(\"microsoft/resnet-50\")\n","\n","# Replace the classifier\n","num_classes = 15\n","model.classifier = nn.Linear(model.classifier.in_features, num_classes)\n","\n","# Step 3: Fine-tune the model\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n","\n","# Training loop\n","for epoch in range(10):  # Adjust the number of epochs as needed\n","    model.train()\n","    for images, labels in train_dataloader:\n","        images, labels = images.to(device), labels.to(device)\n","\n","        optimizer.zero_grad()\n","        outputs = model(images).logits\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","    print(f\"Epoch {epoch+1}/{10}, Loss: {loss.item()}\")\n","\n","# Evaluation\n","model.eval()\n","metric = load_metric(\"accuracy\")\n","for images, labels in val_dataloader:\n","    images, labels = images.to(device), labels.to(device)\n","    with torch.no_grad():\n","        outputs = model(images).logits\n","    predictions = torch.argmax(outputs, dim=1)\n","    metric.add_batch(predictions=predictions, references=labels)\n","\n","accuracy = metric.compute()\n","print(f\"Test Accuracy: {accuracy['accuracy']:.4f}\")\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.3"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}