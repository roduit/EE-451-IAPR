{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"O-nZ59Vf97pK"},"outputs":[],"source":["# -*- coding: utf-8 -*-\n","# -*- authors : Vincent Roduit, Filippo Quadri -*-\n","# -*- date : 2024-05-03 -*-\n","# -*- Last revision: 2024-05-03 -*-\n","# -*- python version : 3.9.18 -*-\n","# -*- Description: Notebook that summarize results-*-"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17512,"status":"ok","timestamp":1716024865892,"user":{"displayName":"Vincent Roduit","userId":"13076277421100865046"},"user_tz":-120},"id":"6941kpJ89_mu","outputId":"3fb2c591-74ba-4294-b7ab-5ff4ad775c79"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["#Prepare Google Colab Environment\n","from google.colab import drive\n","drive.mount('/content/drive')\n","%cd /content/drive/MyDrive/EE-451-IAPR/project/src"]},{"cell_type":"markdown","metadata":{"id":"ZGn195Dx97pN"},"source":["# <center> EE - 451 Image Analysis and Pattern recognition </center>\n","## <center> Ecole Polytechnique Fédérale de Lausanne </center>\n","### <center>Coin Challenge </center>\n","---"]},{"cell_type":"code","execution_count":68,"metadata":{"executionInfo":{"elapsed":255,"status":"ok","timestamp":1716024974302,"user":{"displayName":"Vincent Roduit","userId":"13076277421100865046"},"user_tz":-120},"id":"7K7Y8PkC97pP"},"outputs":[],"source":["#Import libraries\n","import torch\n","import importlib\n","from torch.optim.lr_scheduler import ReduceLROnPlateau\n","from torch import nn\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"code","execution_count":113,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":409,"status":"ok","timestamp":1716024976335,"user":{"displayName":"Vincent Roduit","userId":"13076277421100865046"},"user_tz":-120},"id":"UTG2yckF97pP","outputId":"f1996719-29e2-4bed-9dc2-c18cb9d11c94"},"outputs":[{"name":"stdout","output_type":"stream","text":["The autoreload extension is already loaded. To reload it, use:\n","  %reload_ext autoreload\n"]}],"source":["#Import files\n","import constants\n","importlib.reload(constants)\n","\n","#Classes\n","from data_classes.ref_data import refCoin\n","from data_classes.train_data import trainCoin\n","from data_classes.test_data import testCoin\n","\n","#Functions\n","from visualization import *\n","from pickle_func import *\n","from processing.process_func import *\n","from models.utils import *\n","from processing.data_augmentation import *\n","\n","#Models\n","from models.cnn import Basic_CNN, Advanced_CNN, CnnRadius\n","%load_ext autoreload\n","%autoreload 2\n"]},{"cell_type":"markdown","metadata":{"id":"_5wZnAr697pQ"},"source":["# 1. Load different Datasets"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-JGPRvL197pR"},"outputs":[],"source":["ref_data = refCoin()"]},{"cell_type":"code","execution_count":81,"metadata":{"id":"29XCNbx397pR","outputId":"76e21ae1-d069-4441-a913-425f826cae4d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Loading data from pickle files\n"]}],"source":["train_data = trainCoin(save=False, load_from_pickle=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"95YGqtKe97pS","outputId":"756b3f8d-e599-40c7-9f71-8b4e2aee2f1a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Loading data from pickle files\n"]}],"source":["test_data = testCoin()"]},{"cell_type":"markdown","metadata":{"id":"uaoCU_3M97pS"},"source":["# 2 Processing Data"]},{"cell_type":"code","execution_count":82,"metadata":{"id":"ZKWiHjoQ97pT","outputId":"b467915f-cc84-4905-d6f0-51807cd7d88f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Finding contours\n","Creating masked images\n","Creating coin images\n"]}],"source":["#Process all the images :\n","# 1. clean the images and find the contours\n","# 2. create the masked images\n","# 3. create the coin images\n","# 4. if save = True, save the images and the class in a result folder\n","train_data.proceed_data()"]},{"cell_type":"markdown","metadata":{},"source":["# 3 Create Labels and formating Data for training"]},{"cell_type":"markdown","metadata":{},"source":["## 3.1 Fetch the labels "]},{"cell_type":"code","execution_count":83,"metadata":{"executionInfo":{"elapsed":248,"status":"ok","timestamp":1716024984621,"user":{"displayName":"Vincent Roduit","userId":"13076277421100865046"},"user_tz":-120},"id":"d1FW4ji797pT"},"outputs":[],"source":["conversion_table = get_classes_conv_table()"]},{"cell_type":"code","execution_count":84,"metadata":{"id":"6s1vxbmk97pT"},"outputs":[],"source":["# Associate the labels to the coins\n","coin_labels = get_coin_labels()"]},{"cell_type":"code","execution_count":87,"metadata":{"id":"GfKkLy3w97pU"},"outputs":[],"source":["# Extract the images and the labels + create a dataframe that summarize the data\n","images,radius_infos, labels, df_images_labels = create_data_structure(train_data.coins, train_data.contours, coin_labels, conversion_table)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d5DSzvkP97pU"},"outputs":[],"source":["# Optional : save the coins in ../data/results/coins_classified \n","#           the coins are separated in folders according to their class\n","save_coins_classified(df_images_labels, images)"]},{"cell_type":"markdown","metadata":{},"source":["## 3.2 Data augmentation and train/validation split"]},{"cell_type":"code","execution_count":94,"metadata":{"id":"qhElOdHX97pU"},"outputs":[],"source":["# Create the splits (train and validation)\n","train_images, train_radius, train_labels, val_images, val_radius, val_labels = create_splits(images, radius_infos, labels)"]},{"cell_type":"code","execution_count":95,"metadata":{"id":"z2MkspQE97pU"},"outputs":[],"source":["# Augment the training set with rotations\n","train_images_aug, train_radius_aug, train_labels_aug = augment_set_rotations(train_images, train_radius, train_labels)\n","\n","# Augment the training set with Gaussian blur\n","# train_images_aug, train_radius_aug, train_labels_aug = augment_blur(train_images_aug, train_labels_aug)"]},{"cell_type":"code","execution_count":104,"metadata":{"id":"xwsiBp5n97pU"},"outputs":[],"source":["# Resize the images to 200x200 to decrease the computation time\n","train_images_aug_resized = resize_images(train_images_aug, 200)\n","val_images_resized = resize_images(val_images, 200)"]},{"cell_type":"code","execution_count":108,"metadata":{},"outputs":[],"source":["#Optional : save the datasets in ../data/results/pickle_files\n","save_pickle(result=train_images_aug_resized, file_name='train_images_aug_resized.pkl')\n","save_pickle(result=train_radius_aug, file_name='train_radius_aug.pkl')\n","save_pickle(result=train_labels_aug, file_name='train_labels_aug.pkl')\n","\n","save_pickle(result=val_images, file_name='val_images_resized.pkl')\n","save_pickle(result=val_radius, file_name='val_radius.pkl')\n","save_pickle(result=val_labels, file_name='val_labels.pkl')"]},{"cell_type":"code","execution_count":109,"metadata":{"executionInfo":{"elapsed":1141,"status":"ok","timestamp":1716024988305,"user":{"displayName":"Vincent Roduit","userId":"13076277421100865046"},"user_tz":-120},"id":"6yY0F4U_-NU8"},"outputs":[],"source":["# Optional : Load precomputed data\n","train_images_aug_resized = load_pickle('train_images_aug_resized.pkl')\n","train_images_labels_aug = load_pickle('train_labels_aug.pkl')\n","train_radius_aug = load_pickle('train_radius_aug.pkl')\n","\n","val_images_resized = load_pickle('val_images_resized.pkl')\n","val_radius = load_pickle('val_radius.pkl')\n","val_images_labels = load_pickle('val_labels.pkl')"]},{"cell_type":"markdown","metadata":{"id":"jTOA14mK97pV"},"source":["# 4 Train Neural Network\n"]},{"cell_type":"markdown","metadata":{},"source":["## 4.1 Create Dataloader"]},{"cell_type":"code","execution_count":112,"metadata":{"executionInfo":{"elapsed":2900,"status":"ok","timestamp":1716024992675,"user":{"displayName":"Vincent Roduit","userId":"13076277421100865046"},"user_tz":-120},"id":"p6yY-omk97pV"},"outputs":[],"source":["train_dataloader, val_dataloader = create_dataloader(\n","    train_images=train_images_aug_resized,\n","    train_labels=train_images_labels_aug,\n","    train_radius=train_radius_aug, #Set to None if not needed\n","    val_images=val_images_resized, #Set to None if not needed\n","    val_labels=val_images_labels,\n","    val_radius=val_radius)"]},{"cell_type":"markdown","metadata":{"id":"sDXPXW5m97pV"},"source":["## 4.2 Custom Basic CNN"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":228125,"status":"ok","timestamp":1716025223130,"user":{"displayName":"Vincent Roduit","userId":"13076277421100865046"},"user_tz":-120},"id":"lMOAB3wB97pV","outputId":"50fba308-e131-4dbe-cf2f-c23736b84134"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/10, Loss: 2.2964949739092395, Validation Accuracy: 0.6883\n","Epoch 2/10, Loss: 1.718103261017106, Validation Accuracy: 0.7403\n","Epoch 3/10, Loss: 0.7807000739371538, Validation Accuracy: 0.9221\n","Epoch 4/10, Loss: 2.0474204140315675, Validation Accuracy: 0.8442\n","Epoch 5/10, Loss: 2.791350682638119, Validation Accuracy: 0.7922\n","Epoch 6/10, Loss: 6.755259082910292, Validation Accuracy: 0.7532\n","Epoch 7/10, Loss: 4.072394247674139, Validation Accuracy: 0.8182\n","Epoch 8/10, Loss: 4.198189846734584, Validation Accuracy: 0.8052\n","Epoch 9/10, Loss: 4.379997418846135, Validation Accuracy: 0.7922\n","Epoch 10/10, Loss: 4.464120910213626, Validation Accuracy: 0.7922\n"]}],"source":["image_dim = train_images_aug_resized.shape[1]\n","num_classes = len(conversion_table)\n","# Define the model\n","cnn = Basic_CNN(image_size=image_dim, num_classes=num_classes)\n","\n","# Define the optimizer\n","optimizer = torch.optim.Adam(cnn.parameters(), lr=0.001)\n","# Define the scheduler\n","scheduler = ReduceLROnPlateau(\n","    optimizer, mode=\"min\", factor=0.1, patience=2, verbose=True\n",")\n","criterion = nn.BCEWithLogitsLoss()\n","\n","# Train the model\n","cnn.train_model(\n","    optimizer,\n","    scheduler,\n","    train_dataloader,\n","    val_dataloader,\n",")"]},{"cell_type":"markdown","metadata":{},"source":["## 4.3 Custom Advanced CNN"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Define the model\n","cnn = Advanced_CNN(image_size=image_dim, num_classes=num_classes)\n","\n","# Define the optimizer\n","optimizer = torch.optim.Adam(cnn.parameters(), lr=0.001)\n","# Define the scheduler\n","scheduler = ReduceLROnPlateau(\n","    optimizer, mode=\"min\", factor=0.1, patience=2, verbose=True\n",")\n","criterion = nn.BCEWithLogitsLoss()\n","\n","# Train the model\n","cnn.train_model(\n","    optimizer,\n","    scheduler,\n","    train_dataloader,\n","    val_dataloader,\n",")"]},{"cell_type":"markdown","metadata":{},"source":["## 4.3 Custom CNN with Radius Informations"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Define the model\n","cnn = CnnRadius(image_size=image_dim, num_classes=num_classes)\n","\n","# Define the optimizer\n","optimizer = torch.optim.Adam(cnn.parameters(), lr=0.001)\n","# Define the scheduler\n","scheduler = ReduceLROnPlateau(\n","    optimizer, mode=\"min\", factor=0.1, patience=2, verbose=True\n",")\n","criterion = nn.BCEWithLogitsLoss()\n","\n","# Train the model\n","cnn.train_model(\n","    optimizer,\n","    scheduler,\n","    train_dataloader,\n","    val_dataloader,\n",")"]},{"cell_type":"markdown","metadata":{"id":"6sscc9fm97pV"},"source":["## 4.4 RESNET-50"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K8ocQLvN97pV"},"outputs":[],"source":["from transformers import AutoImageProcessor, ResNetForImageClassification\n","from torchvision import transforms\n","from datasets import load_metric\n","\n","# Step 2: Modify the final layer\n","model = ResNetForImageClassification.from_pretrained(\"microsoft/resnet-50\")\n","\n","# Replace the classifier\n","num_classes = 15\n","model.classifier = nn.Linear(model.classifier.in_features, num_classes)\n","\n","# Step 3: Fine-tune the model\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n","\n","# Training loop\n","for epoch in range(10):  # Adjust the number of epochs as needed\n","    model.train()\n","    for images, labels in train_dataloader:\n","        images, labels = images.to(device), labels.to(device)\n","\n","        optimizer.zero_grad()\n","        outputs = model(images).logits\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","    print(f\"Epoch {epoch+1}/{10}, Loss: {loss.item()}\")\n","\n","# Evaluation\n","model.eval()\n","metric = load_metric(\"accuracy\")\n","for images, labels in val_dataloader:\n","    images, labels = images.to(device), labels.to(device)\n","    with torch.no_grad():\n","        outputs = model(images).logits\n","    predictions = torch.argmax(outputs, dim=1)\n","    metric.add_batch(predictions=predictions, references=labels)\n","\n","accuracy = metric.compute()\n","print(f\"Test Accuracy: {accuracy['accuracy']:.4f}\")\n"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.3"}},"nbformat":4,"nbformat_minor":0}
